# Streamlit PDF â†’ Clean Text (with OCR) Web App
# -------------------------------------------------
# This app extracts ONLY the main text from PDFs (native or scanned) and
# excludes images, charts, page numbers, repeating headers/footers, and footnotes.
# It is designed to run on Streamlit Community Cloud (no system Tesseract needed).
# OCR is done with EasyOCR (PyTorch), and native text is read via PyMuPDF.
#
# Usage (local): `streamlit run app.py`
# Deployment: push this file + requirements.txt to GitHub and deploy on Streamlit Cloud.

import io
import re
from typing import List, Tuple, Dict

import streamlit as st
import fitz  # PyMuPDF
import numpy as np
from PIL import Image

# EasyOCR is heavy to import; do it lazily when needed.
_EASYOCR_READER = None

def get_easyocr_reader(lang_codes: List[str]):
    global _EASYOCR_READER
    if _EASYOCR_READER is None:
        import easyocr  # type: ignore
        _EASYOCR_READER = easyocr.Reader(lang_codes, gpu=False)
    return _EASYOCR_READER

# ------------------------------
# Text Cleaning & Heuristics
# ------------------------------
HEADER_FOOTER_SAMPLE_LINES = 3  # take top/bottom N lines per page for repetition detection
HEADER_FOOTER_THRESHOLD = 0.5   # consider header/footer if it appears on > 50% pages

PAGE_NUMBER_PATTERNS = [
    re.compile(r"^\s*\d+\s*$"),                   # "12"
    re.compile(r"^\s*\d+\s*/\s*\d+\s*$"),      # "12/300"
    re.compile(r"^\s*page\s*\d+\s*$", re.I),     # "Page 12"
    re.compile(r"^\s*\d+\s*of\s*\d+\s*$", re.I) # "12 of 300"
]

FOOTNOTE_LINE_PATTERN = re.compile(r"^\s*\(?\d{1,3}[a-zA-Z\)]?\s+.*")  # e.g., "1 Text...", "(12) Text..."
FOOTNOTE_MARK_INLINE = re.compile(r"(?<!\w)(\d{1,3}|[ivxlcdm]{1,4})\s*$", re.I)  # trailing small ref numbers/roman


def normalize_line(s: str) -> str:
    s = s.replace("\u00ad", "")  # soft hyphen
    s = re.sub(r"\s+", " ", s)
    return s.strip()


def is_probable_page_number(line: str) -> bool:
    for pat in PAGE_NUMBER_PATTERNS:
        if pat.match(line):
            return True
    return False


def gather_repeating_headers_footers(pages_lines: List[List[str]]) -> Tuple[set, set]:
    """Find lines that repeat across many pages at the very top/bottom."""
    top_counts: Dict[str, int] = {}
    bot_counts: Dict[str, int] = {}
    total_pages = len(pages_lines)

    for lines in pages_lines:
        tops = lines[:HEADER_FOOTER_SAMPLE_LINES]
        bots = lines[-HEADER_FOOTER_SAMPLE_LINES:] if len(lines) >= HEADER_FOOTER_SAMPLE_LINES else lines[-1:]
        for t in tops:
            top_counts[t] = top_counts.get(t, 0) + 1
        for b in bots:
            bot_counts[b] = bot_counts.get(b, 0) + 1

    top_repeats = {t for t, c in top_counts.items() if c / total_pages >= HEADER_FOOTER_THRESHOLD}
    bot_repeats = {b for b, c in bot_counts.items() if c / total_pages >= HEADER_FOOTER_THRESHOLD}
    return top_repeats, bot_repeats


def stitch_paragraphs(lines: List[str]) -> str:
    """Merge broken lines into paragraphs, remove hyphenation at line ends."""
    out = []
    buf = ""
    for line in lines:
        if not line:
            if buf:
                out.append(buf)
                buf = ""
            continue
        # merge hyphenated line endings
        if buf.endswith("-"):
            buf = buf[:-1] + line
        else:
            if buf:
                # If line looks like a new paragraph (starts with indent or is short title), break
                if re.match(r"^\s{2,}\S", line) or len(line) <= 3:
                    out.append(buf)
                    buf = line
                else:
                    buf += " " + line
            else:
                buf = line
    if buf:
        out.append(buf)
    return "\n\n".join(out)


# ------------------------------
# PDF Extraction
# ------------------------------

def extract_native_text_blocks(page: fitz.Page) -> List[Tuple[str, Tuple[float, float, float, float], float]]:
    """Return list of (text, bbox, fontsize) for each line-ish block from PyMuPDF."""
    blocks = page.get_text("blocks", flags=fitz.TEXT_PRESERVE_LIGATURES | fitz.TEXT_PRESERVE_WHITESPACE)
    lines = []
    for x0, y0, x1, y1, text, block_no, block_type in blocks:  # type: ignore
        if not text or text.isspace():
            continue
        # Split block text into lines but keep same bbox per rough line
        for raw_line in text.splitlines():
            line = normalize_line(raw_line)
            if line:
                # font size is not directly provided at block level; approximate from height
                fontsize = max(8.0, (y1 - y0) / max(1, text.count("\n") + 1))
                lines.append((line, (x0, y0, x1, y1), fontsize))
    # Sort by vertical position
    lines.sort(key=lambda it: (it[1][1], it[1][0]))
    return lines


def extract_text_with_easyocr(page: fitz.Page, lang_codes: List[str]) -> List[Tuple[str, Tuple[float, float, float, float], float]]:
    pix = page.get_pixmap(dpi=220)
    img = Image.open(io.BytesIO(pix.tobytes()))
    arr = np.array(img)
    reader = get_easyocr_reader(lang_codes)
    results = reader.readtext(arr, detail=1, paragraph=False)
    # results: list of [bbox, text, confidence]
    lines = []
    for bbox, raw, conf in results:
        line = normalize_line(raw)
        if not line:
            continue
        xs = [p[0] for p in bbox]
        ys = [p[1] for p in bbox]
        x0, y0, x1, y1 = min(xs), min(ys), max(xs), max(ys)
        fontsize = max(8.0, (y1 - y0))
        lines.append((line, (x0, y0, x1, y1), fontsize))
    lines.sort(key=lambda it: (it[1][1], it[1][0]))
    return lines


def clean_document_lines(pages_lines_with_geo: List[List[Tuple[str, Tuple[float, float, float, float], float]]]) -> str:
    # Convert per-page to simple line lists for header/footer detection
    simple_pages = [[ln for (ln, _, _) in page] for page in pages_lines_with_geo]
    top_repeats, bot_repeats = gather_repeating_headers_footers(simple_pages)

    cleaned_all: List[str] = []

    for page_idx, page in enumerate(pages_lines_with_geo):
        if not page:
            continue
        # Compute page height for positional heuristics
        page_heights = [bbox[3] for (_, bbox, _) in page]
        page_height = max(page_heights) if page_heights else 1000
        bottom_cut = page_height * 0.15  # bottom 15% treated as potential footnote zone

        page_clean: List[str] = []
        for line, bbox, fontsize in page:
            txt = line
            if txt in top_repeats or txt in bot_repeats:
                continue
            if is_probable_page_number(txt):
                continue
            # remove inline trailing footnote markers like "text 12" or roman numerals
            txt = FOOTNOTE_MARK_INLINE.sub("", txt).strip()
            if not txt:
                continue
            # drop short noise
            if len(txt) <= 2:
                continue
            # drop footnotes: small font & near bottom or pattern
            y1 = bbox[3]
            if y1 >= page_height - bottom_cut:
                if FOOTNOTE_LINE_PATTERN.match(txt) or fontsize < 10:
                    continue
            page_clean.append(txt)

        # collapse consecutive duplicate lines within page
        dedup = []
        for t in page_clean:
            if not dedup or dedup[-1] != t:
                dedup.append(t)
        cleaned_all.extend(dedup + [""])  # blank line as paragraph separator

    return stitch_paragraphs(cleaned_all)


# ------------------------------
# Streamlit UI
# ------------------------------

st.set_page_config(page_title="PDF â†’ Clean Text (OCR)", page_icon="ðŸ§¹", layout="centered")
st.title("PDF â†’ Clean Text (with OCR)")
st.write("Upload one or more PDFs. Iâ€™ll return **only the main body text** â€” no images, charts, page numbers, repeated headers/footers, or footnotes.")

with st.expander("OCR & Extraction Options"):
    use_ocr_fallback = st.checkbox("Use OCR fallback if a page has little/no native text", value=True)
    ocr_langs = st.text_input("OCR languages (comma-separated EasyOCR codes)", value="en")
    header_footer_threshold = st.slider("Header/Footer repetition threshold", 0.3, 0.9, 0.5, 0.1)
    global HEADER_FOOTER_THRESHOLD
    HEADER_FOOTER_THRESHOLD = float(header_footer_threshold)

uploaded = st.file_uploader("Drop PDFs here", type=["pdf"], accept_multiple_files=True)

if uploaded:
    for file in uploaded:
        st.subheader(file.name)
        try:
            data = file.read()
            doc = fitz.open(stream=data, filetype="pdf")
            pages_lines_with_geo: List[List[Tuple[str, Tuple[float, float, float, float], float]]] = []

            for i in range(len(doc)):
                page = doc.load_page(i)
                native = extract_native_text_blocks(page)
                native_text_len = sum(len(t) for (t, _, _) in native)

                if use_ocr_fallback and native_text_len < 80:  # likely scanned
                    try:
                        langs = [c.strip() for c in ocr_langs.split(",") if c.strip()]
                        ocr_lines = extract_text_with_easyocr(page, langs)
                        lines = ocr_lines if len(ocr_lines) > len(native) else native
                    except Exception as e:
                        st.info(f"OCR failed on page {i+1}: {e}. Using native text only.")
                        lines = native
                else:
                    lines = native

                # Keep just text/bbox/size
                pages_lines_with_geo.append(lines)

            cleaned_text = clean_document_lines(pages_lines_with_geo)

            # Download button
            txt_bytes = cleaned_text.encode("utf-8")
            out_name = re.sub(r"\.pdf$", "", file.name, flags=re.I) + "_clean.txt"
            st.download_button(
                label=f"Download cleaned text for {file.name}",
                data=txt_bytes,
                file_name=out_name,
                mime="text/plain"
            )

            with st.expander("Preview cleaned text"):
                st.text_area("", cleaned_text[:100000], height=300)

        except Exception as e:
            st.error(f"Failed to process {file.name}: {e}")

# ------------------------------
